{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbe816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    r2_score, \n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    explained_variance_score\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import shap\n",
    "from scipy.stats import ks_2samp, wasserstein_distance, energy_distance\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Configuración visual\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "colors = sns.color_palette(\"mako\", 10)\n",
    "\n",
    "# Establecer semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MONITOREO DE RENDIMIENTO DEL MODELO CON ANÁLISIS SHAP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear un directorio para las gráficas\n",
    "import os\n",
    "if not os.path.exists('model_monitoring'):\n",
    "    os.makedirs('model_monitoring')\n",
    "\n",
    "# Cargar el dataset\n",
    "print(\"\\nCargando datos...\")\n",
    "housing = fetch_california_housing()\n",
    "data = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "data['target'] = housing.target\n",
    "\n",
    "# Dividir en train/test\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Simular datos con drift para comparación\n",
    "print(\"Preparando datos de referencia y actuales...\")\n",
    "current_data = test_data.copy()\n",
    "# Introducir drift artificial en algunas características\n",
    "current_data['MedInc'] = current_data['MedInc'] * 1.2\n",
    "current_data['AveRooms'] = current_data['AveRooms'] + 0.5\n",
    "\n",
    "# Preparar conjuntos\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data['target']\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "X_current = current_data.drop('target', axis=1)\n",
    "y_current = current_data['target']\n",
    "\n",
    "# Entrenar modelo\n",
    "print(\"Entrenando modelo...\")\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generar predicciones\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_current = model.predict(X_current)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "results_test = pd.DataFrame({\n",
    "    'actual': y_test, \n",
    "    'predicted': y_pred_test, \n",
    "    'residual': y_test - y_pred_test,\n",
    "    'abs_error': np.abs(y_test - y_pred_test),\n",
    "    'pct_error': np.abs((y_test - y_pred_test) / y_test) * 100\n",
    "})\n",
    "\n",
    "results_current = pd.DataFrame({\n",
    "    'actual': y_current,\n",
    "    'predicted': y_pred_current,\n",
    "    'residual': y_current - y_pred_current,\n",
    "    'abs_error': np.abs(y_current - y_pred_current),\n",
    "    'pct_error': np.abs((y_current - y_pred_current) / y_current) * 100\n",
    "})\n",
    "\n",
    "# 1. EVALUACIÓN DEL RENDIMIENTO DEL MODELO\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"1. MÉTRICAS DE RENDIMIENTO DEL MODELO\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calcular métricas básicas\n",
    "metrics = {\n",
    "    'MSE': [mean_squared_error(y_test, y_pred_test), mean_squared_error(y_current, y_pred_current)],\n",
    "    'RMSE': [np.sqrt(mean_squared_error(y_test, y_pred_test)), np.sqrt(mean_squared_error(y_current, y_pred_current))],\n",
    "    'MAE': [mean_absolute_error(y_test, y_pred_test), mean_absolute_error(y_current, y_pred_current)],\n",
    "    'MAPE (%)': [mean_absolute_percentage_error(y_test, y_pred_test) * 100, mean_absolute_percentage_error(y_current, y_pred_current) * 100],\n",
    "    'R²': [r2_score(y_test, y_pred_test), r2_score(y_current, y_pred_current)],\n",
    "    'Var. Explicada': [explained_variance_score(y_test, y_pred_test), explained_variance_score(y_current, y_pred_current)]\n",
    "}\n",
    "\n",
    "# Crear tabla comparativa de métricas\n",
    "metrics_df = pd.DataFrame(metrics, index=['Datos de Referencia', 'Datos Actuales'])\n",
    "print(metrics_df.round(4))\n",
    "\n",
    "# Calcular diferencias\n",
    "diff_df = pd.DataFrame({\n",
    "    'Métrica': metrics_df.columns,\n",
    "    'Referencia': metrics_df.iloc[0].values,\n",
    "    'Actual': metrics_df.iloc[1].values,\n",
    "    'Diferencia': metrics_df.iloc[1].values - metrics_df.iloc[0].values,\n",
    "    'Cambio (%)': (metrics_df.iloc[1].values - metrics_df.iloc[0].values) / metrics_df.iloc[0].values * 100\n",
    "})\n",
    "print(\"\\nCambios en las métricas:\")\n",
    "print(diff_df.round(4))\n",
    "\n",
    "# 2. ANÁLISIS DE DRIFT AVANZADO EN VARIABLES\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"2. ANÁLISIS AVANZADO DE DRIFT EN VARIABLES\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calcular estadísticas para cada columna\n",
    "drift_analysis = []\n",
    "\n",
    "for col in X_test.columns:\n",
    "    # Estadísticas básicas\n",
    "    ref_mean = X_test[col].mean()\n",
    "    ref_std = X_test[col].std()\n",
    "    curr_mean = X_current[col].mean()\n",
    "    curr_std = X_current[col].std()\n",
    "    \n",
    "    # Calcular métricas de cambio\n",
    "    mean_change_pct = (curr_mean - ref_mean) / ref_mean * 100 if ref_mean != 0 else np.inf\n",
    "    std_change_pct = (curr_std - ref_std) / ref_std * 100 if ref_std != 0 else np.inf\n",
    "    \n",
    "    # Test de Kolmogorov-Smirnov (medida estadística de drift)\n",
    "    ks_stat, ks_pval = ks_2samp(X_test[col], X_current[col])\n",
    "    \n",
    "    # Distancia de Wasserstein (Earth Mover's Distance)\n",
    "    w_distance = wasserstein_distance(X_test[col], X_current[col])\n",
    "    # Normalizar por el rango para hacerla comparable entre variables\n",
    "    w_distance_norm = w_distance / (X_test[col].max() - X_test[col].min())\n",
    "    \n",
    "    # Distancia Energy (más sensible que KS para distribuciones multidimensionales)\n",
    "    e_distance = energy_distance(X_test[col], X_current[col])\n",
    "    # Normalizar por el rango\n",
    "    e_distance_norm = e_distance / (X_test[col].max() - X_test[col].min())\n",
    "    \n",
    "    # Calcular distancia de Jensen-Shannon\n",
    "    min_val = min(X_test[col].min(), X_current[col].min())\n",
    "    max_val = max(X_test[col].max(), X_current[col].max())\n",
    "    x_range = np.linspace(min_val, max_val, 1000)\n",
    "    \n",
    "    # KDE para datos de referencia y actuales\n",
    "    ref_kde = gaussian_kde(X_test[col])\n",
    "    ref_pdf = ref_kde(x_range)\n",
    "    ref_pdf = ref_pdf / np.sum(ref_pdf)\n",
    "    \n",
    "    curr_kde = gaussian_kde(X_current[col])\n",
    "    curr_pdf = curr_kde(x_range)\n",
    "    curr_pdf = curr_pdf / np.sum(curr_pdf)\n",
    "    \n",
    "    js_distance = jensenshannon(ref_pdf, curr_pdf)\n",
    "    \n",
    "    # Determinar si hay drift significativo basado en múltiples criterios\n",
    "    # 1. KS p-value < 0.05 significa distribuciones estadísticamente diferentes\n",
    "    # 2. JS distance > 0.1 suele indicar drift significativo\n",
    "    # 3. Wasserstein norm > 0.1 indica cambio sustancial\n",
    "    drift_score = (\n",
    "        (1 if ks_pval < 0.05 else 0) + \n",
    "        (1 if js_distance > 0.1 else 0) + \n",
    "        (1 if w_distance_norm > 0.1 else 0)\n",
    "    )\n",
    "    \n",
    "    # Clasificación del drift\n",
    "    if drift_score == 0:\n",
    "        drift_level = \"NO\"\n",
    "    elif drift_score == 1:\n",
    "        drift_level = \"LEVE\"\n",
    "    elif drift_score == 2:\n",
    "        drift_level = \"MODERADO\"\n",
    "    else:\n",
    "        drift_level = \"SEVERO\"\n",
    "    \n",
    "    drift_analysis.append({\n",
    "        'Feature': col,\n",
    "        'Ref_Mean': ref_mean,\n",
    "        'Curr_Mean': curr_mean,\n",
    "        'Mean_Change(%)': mean_change_pct,\n",
    "        'Ref_Std': ref_std,\n",
    "        'Curr_Std': curr_std,\n",
    "        'Std_Change(%)': std_change_pct,\n",
    "        'KS_Stat': ks_stat,\n",
    "        'KS_PValue': ks_pval,\n",
    "        'Wasserstein': w_distance_norm,\n",
    "        'Energy': e_distance_norm,\n",
    "        'JS_Distance': js_distance,\n",
    "        'Drift_Score': drift_score,\n",
    "        'Drift_Level': drift_level\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con resultados de drift\n",
    "drift_df = pd.DataFrame(drift_analysis)\n",
    "drift_df = drift_df.sort_values('Drift_Score', ascending=False)\n",
    "\n",
    "print(\"\\nAnálisis de drift en variables (ordenado por severidad del drift):\")\n",
    "print(drift_df[['Feature', 'Mean_Change(%)', 'KS_PValue', 'Wasserstein', 'JS_Distance', 'Drift_Level']].round(4))\n",
    "\n",
    "# Visualizar cambios en las distribuciones para las variables con mayor drift\n",
    "top_drift_features = drift_df[drift_df['Drift_Level'] != \"NO\"]['Feature'].tolist()[:3]  # Hasta 3 con drift\n",
    "\n",
    "for feature in top_drift_features:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Histogramas con KDE\n",
    "    sns.histplot(X_test[feature], color=colors[0], label='Referencia', kde=True, alpha=0.6)\n",
    "    sns.histplot(X_current[feature], color=colors[1], label='Actual', kde=True, alpha=0.6)\n",
    "    \n",
    "    # Añadir estadísticas al gráfico\n",
    "    feature_stats = drift_df[drift_df['Feature'] == feature].iloc[0]\n",
    "    plt.title(f'Drift en {feature} (Nivel: {feature_stats[\"Drift_Level\"]})')\n",
    "    plt.text(0.02, 0.95, \n",
    "             f'KS p-valor: {feature_stats[\"KS_PValue\"]:.4f}\\n'\n",
    "             f'Jensen-Shannon: {feature_stats[\"JS_Distance\"]:.4f}\\n'\n",
    "             f'Wasserstein: {feature_stats[\"Wasserstein\"]:.4f}',\n",
    "             transform=plt.gca().transAxes, \n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'model_monitoring/drift_{feature}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Visualizar todas las métricas de drift para cada variable\n",
    "plt.figure(figsize=(14, 8))\n",
    "metrics_to_plot = ['KS_Stat', 'Wasserstein', 'JS_Distance']\n",
    "drift_plot_data = drift_df.melt(\n",
    "    id_vars=['Feature', 'Drift_Level'], \n",
    "    value_vars=metrics_to_plot,\n",
    "    var_name='Métrica', \n",
    "    value_name='Valor'\n",
    ")\n",
    "sns.barplot(data=drift_plot_data, x='Feature', y='Valor', hue='Métrica')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Comparación de métricas de drift por variable')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/drift_metrics_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. ANÁLISIS GLOBAL DE VALORES SHAP\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"3. ANÁLISIS GLOBAL DE VALORES SHAP\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Crear el explicador SHAP\n",
    "print(\"Calculando valores SHAP...\")\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calcular valores SHAP para el conjunto de referencia\n",
    "shap_values_test = explainer(X_test)\n",
    "\n",
    "# 3.1 Gráfico de resumen global (SHAP Summary Plot)\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_test.values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title('Importancia Global de Variables (SHAP)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/shap_global_importance.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values_test.values, X_test, show=False)\n",
    "plt.title('Impacto y Distribución de Variables (SHAP)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/shap_global_summary.png')\n",
    "plt.close()\n",
    "\n",
    "# 3.2 Gráficos de dependencia para las 3 variables más importantes\n",
    "top_features = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': np.abs(shap_values_test.values).mean(0)\n",
    "}).sort_values('Importance', ascending=False)['Feature'].head(3).tolist()\n",
    "\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    feature_idx = list(X_test.columns).index(feature)\n",
    "    shap.dependence_plot(feature_idx, shap_values_test.values, X_test, show=False)\n",
    "    plt.title(f'Gráfico de Dependencia SHAP para {feature}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'model_monitoring/shap_dependence_{feature}.png')\n",
    "    plt.close()\n",
    "\n",
    "# 3.3 Comparar valores SHAP entre datos de referencia y actuales\n",
    "print(\"\\nComparando valores SHAP entre datos de referencia y actuales...\")\n",
    "shap_values_current = explainer(X_current)\n",
    "\n",
    "# Calcular la media absoluta de los valores SHAP para cada característica\n",
    "shap_comparison = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'SHAP_Ref': np.abs(shap_values_test.values).mean(0),\n",
    "    'SHAP_Current': np.abs(shap_values_current.values).mean(0)\n",
    "})\n",
    "\n",
    "shap_comparison['SHAP_Change'] = shap_comparison['SHAP_Current'] - shap_comparison['SHAP_Ref']\n",
    "shap_comparison['SHAP_Change_Pct'] = (shap_comparison['SHAP_Change'] / shap_comparison['SHAP_Ref']) * 100\n",
    "shap_comparison = shap_comparison.sort_values('SHAP_Change_Pct', ascending=False)\n",
    "\n",
    "print(\"\\nCambios en la importancia de variables (SHAP):\")\n",
    "print(shap_comparison.round(4))\n",
    "\n",
    "# Visualizar cambios en importancia SHAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap_comp_plot = pd.melt(\n",
    "    shap_comparison, \n",
    "    id_vars=['Feature'], \n",
    "    value_vars=['SHAP_Ref', 'SHAP_Current'], \n",
    "    var_name='Dataset', \n",
    "    value_name='SHAP Value'\n",
    ")\n",
    "sns.barplot(data=shap_comp_plot, x='Feature', y='SHAP Value', hue='Dataset')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Comparación de valores SHAP entre datos de referencia y actuales')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/shap_importance_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. ANÁLISIS DE UN CASO PARTICULAR CON SHAP\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"4. ANÁLISIS DE UN CASO PARTICULAR CON SHAP\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITBA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
