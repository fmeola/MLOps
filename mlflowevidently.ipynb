{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8c6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import ClassificationPreset\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b908c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/student-dataset-v1.csv\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Result'] = le.fit_transform(df['Result'])\n",
    "\n",
    "X = df.drop(columns=['Result'])  \n",
    "y = df['Result']  \n",
    "\n",
    "# Encode categorical variables \n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967931dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guill\\OneDrive\\Documentos\\simplegit\\ITBA\\ITBA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "X_train['prediction'] = lr_model.predict_proba(X_train)[:, 1]\n",
    "X_test['prediction'] = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "X_train['target'] = y_train\n",
    "X_test['target'] = y_test\n",
    "\n",
    "lr_class_report = Report(metrics=[ClassificationPreset()])\n",
    "lr_class_report.run(reference_data=X_train, current_data=X_test)\n",
    "\n",
    "lr_class_report.save(\"json_reports/lr_report_v1.json\")\n",
    "\n",
    "# Load JSON data\n",
    "with open('json_reports/lr_report_v1.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f139cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression v1 Accuracy: 0.9655172413793104\n"
     ]
    }
   ],
   "source": [
    "lr_accuracy_v1 = None\n",
    "metric_results = data['suite']['metric_results']\n",
    "\n",
    "for result in metric_results:\n",
    "    if 'current' in result:\n",
    "        lr_accuracy_v1 = result['current'].get('accuracy')\n",
    "        if lr_accuracy_v1 is not None:\n",
    "            break\n",
    "\n",
    "if lr_accuracy_v1 is not None:\n",
    "    print(\"Logistic Regression v1 Accuracy:\", lr_accuracy_v1)\n",
    "else:\n",
    "    print(\"Accuracy not found in the JSON data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f644e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.set_tracking_uri(\"http://localhost:5000\")  # o la IP donde est√© el Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de89ca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/15 22:17:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RunInfo: artifact_uri='file:///c:/Users/guill/OneDrive/Documentos/simplegit/ITBA/mlruns/869127321442836481/1d6465ef11984e5d8f7af5612a33e005/artifacts', end_time=None, experiment_id='869127321442836481', lifecycle_stage='active', run_id='1d6465ef11984e5d8f7af5612a33e005', run_name='spiffy-squid-391', run_uuid='1d6465ef11984e5d8f7af5612a33e005', start_time=1747358261816, status='RUNNING', user_id='guill'>\n",
      "üèÉ View run spiffy-squid-391 at: http://localhost:5000/#/experiments/869127321442836481/runs/1d6465ef11984e5d8f7af5612a33e005\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/869127321442836481\n"
     ]
    }
   ],
   "source": [
    "# Log into MLflow\n",
    "client = MlflowClient()\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment('Monitoring with EvidentlyAI')\n",
    "\n",
    "# Start new run\n",
    "with mlflow.start_run() as run: \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", lr_accuracy_v1)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(lr_model, \"logistic_regression_model\")\n",
    "\n",
    "    # Print run info\n",
    "    print(run.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5ce37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guill\\OneDrive\\Documentos\\simplegit\\ITBA\\ITBA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "2025/05/15 22:17:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 529ba0760f984dbc969ccf505e337b12\n",
      "Metrics logged: {'accuracy': 0.7241379310344828, 'precision': 0.7037037037037037, 'recall': 1.0, 'f1_score': None, 'roc_auc': 0.7105263157894737, 'log_loss': 0.6472448466998987}\n",
      "üèÉ View run glamorous-mole-584 at: http://localhost:5000/#/experiments/869127321442836481/runs/529ba0760f984dbc969ccf505e337b12\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/869127321442836481\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import ClassificationPreset\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"datasets/student-dataset-v1.csv\")\n",
    "\n",
    "# Encode target variable\n",
    "le = LabelEncoder()\n",
    "df['Result'] = le.fit_transform(df['Result'])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['Result'])\n",
    "y = df['Result']\n",
    "\n",
    "# Encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Add predictions and target for Evidently\n",
    "X_train['prediction'] = lr_model.predict_proba(X_train)[:, 1]\n",
    "X_test['prediction'] = lr_model.predict_proba(X_test)[:, 1]\n",
    "X_train['target'] = y_train\n",
    "X_test['target'] = y_test\n",
    "\n",
    "# Generate Evidently report\n",
    "lr_class_report = Report(metrics=[ClassificationPreset()])\n",
    "lr_class_report.run(reference_data=X_train, current_data=X_test)\n",
    "\n",
    "# Save report as JSON\n",
    "lr_class_report.save(\"json_reports/lr_report_v1.json\")\n",
    "\n",
    "# Load JSON data\n",
    "with open('json_reports/lr_report_v1.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract metrics from Evidently report\n",
    "metrics = {}\n",
    "metric_results = data['suite']['metric_results']\n",
    "\n",
    "for result in metric_results:\n",
    "    if 'current' in result:\n",
    "        metrics['accuracy'] = result['current'].get('accuracy')\n",
    "        metrics['precision'] = result['current'].get('precision')\n",
    "        metrics['recall'] = result['current'].get('recall')\n",
    "        metrics['f1_score'] = result['current'].get('f1_score')\n",
    "        metrics['roc_auc'] = result['current'].get('roc_auc')\n",
    "        metrics['log_loss'] = result['current'].get('log_loss')\n",
    "        break\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "#mlflow.set_tracking_uri(\"http://localhost:5000\")  # Adjust if needed\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment('Monitoring with EvidentlyAI')\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Log metrics to MLflow\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        if metric_value is not None:\n",
    "            mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(lr_model, \"logistic_regression_model\")\n",
    "\n",
    "    # Print run info\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(\"Metrics logged:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d0771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaleido\n",
      "  Using cached kaleido-0.2.1-py2.py3-none-win_amd64.whl.metadata (15 kB)\n",
      "Using cached kaleido-0.2.1-py2.py3-none-win_amd64.whl (65.9 MB)\n",
      "Installing collected packages: kaleido\n",
      "Successfully installed kaleido-0.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2da19563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guill\\OneDrive\\Documentos\\simplegit\\ITBA\\ITBA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 109\u001b[0m\n\u001b[0;32m    105\u001b[0m fig\u001b[38;5;241m.\u001b[39mwrite_html(plot_html_path)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m#fig.write_image(plot_png_path)\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Optional: Display the plot (e.g., in Jupyter)\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Set MLflow tracking URI\u001b[39;00m\n\u001b[0;32m    112\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tracking_uri(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:5000\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Adjust if needed\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\simplegit\\ITBA\\ITBA\\lib\\site-packages\\plotly\\basedatatypes.py:3410\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3378\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3379\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3406\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[0;32m   3407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3408\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[1;32m-> 3410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\simplegit\\ITBA\\ITBA\\lib\\site-packages\\plotly\\io\\_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         )\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         )\n\u001b[0;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import ClassificationPreset\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "\n",
    "# Create a directory for saving plots\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"datasets/student-dataset-v1.csv\")\n",
    "\n",
    "# Encode target variable\n",
    "le = LabelEncoder()\n",
    "df['Result'] = le.fit_transform(df['Result'])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['Result'])\n",
    "y = df['Result']\n",
    "\n",
    "# Encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Add predictions and target for Evidently\n",
    "X_train['prediction'] = lr_model.predict_proba(X_train)[:, 1]\n",
    "X_test['prediction'] = lr_model.predict_proba(X_test)[:, 1]\n",
    "X_train['target'] = y_train\n",
    "X_test['target'] = y_test\n",
    "\n",
    "# Generate Evidently report\n",
    "lr_class_report = Report(metrics=[ClassificationPreset()])\n",
    "lr_class_report.run(reference_data=X_train, current_data=X_test)\n",
    "\n",
    "# Save Evidently report as HTML (interactive visualizations)\n",
    "html_report_path = \"plots/lr_classification_report.html\"\n",
    "lr_class_report.save_html(html_report_path)\n",
    "\n",
    "# Save report as JSON for metric extraction\n",
    "json_report_path = \"json_reports/lr_report_v1.json\"\n",
    "lr_class_report.save(json_report_path)\n",
    "\n",
    "# Load JSON data to extract metrics\n",
    "with open(json_report_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract metrics\n",
    "metrics = {}\n",
    "metric_results = data['suite']['metric_results']\n",
    "for result in metric_results:\n",
    "    if 'current' in result:\n",
    "        metrics['accuracy'] = result['current'].get('accuracy')\n",
    "        metrics['precision'] = result['current'].get('precision')\n",
    "        metrics['recall'] = result['current'].get('recall')\n",
    "        metrics['f1_score'] = result['current'].get('f1_score')\n",
    "        metrics['roc_auc'] = result['current'].get('roc_auc')\n",
    "        metrics['log_loss'] = result['current'].get('log_loss')\n",
    "        break\n",
    "\n",
    "# Create a Plotly bar plot for metrics\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for each metric\n",
    "metric_names = list(metrics.keys())\n",
    "metric_values = [v for v in metrics.values() if v is not None]\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=metric_names,\n",
    "        y=metric_values,\n",
    "        text=[f\"{v:.3f}\" for v in metric_values],\n",
    "        textposition=\"auto\",\n",
    "        marker=dict(color=metric_values, colorscale=\"Viridis\", showscale=True),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout for a more appealing look\n",
    "fig.update_layout(\n",
    "    title=\"Classification Metrics for Logistic Regression\",\n",
    "    xaxis_title=\"Metric\",\n",
    "    yaxis_title=\"Value\",\n",
    "    template=\"plotly_dark\",  # Dark theme for a modern look\n",
    "    showlegend=False,\n",
    "    height=500,\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Save the plot as HTML (interactive) and PNG (static)\n",
    "plot_html_path = \"plots/classification_metrics.html\"\n",
    "plot_png_path = \"plots/classification_metrics.png\"\n",
    "fig.write_html(plot_html_path)\n",
    "#fig.write_image(plot_png_path)\n",
    "\n",
    "# Optional: Display the plot (e.g., in Jupyter)\n",
    "fig.show()\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  # Adjust if needed\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment('Monitoring with EvidentlyAI')\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Log metrics to MLflow\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        if metric_value is not None:\n",
    "            mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(lr_model, \"logistic_regression_model\")\n",
    "\n",
    "    # Log Evidently HTML report and Plotly plots as artifacts\n",
    "    mlflow.log_artifact(html_report_path)\n",
    "    mlflow.log_artifact(plot_html_path)\n",
    "    #mlflow.log_artifact(plot_png_path)\n",
    "\n",
    "    # Print run info\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(\"Metrics logged:\", metrics)\n",
    "    print(f\"Artifacts logged: {html_report_path}, {plot_html_path}, {plot_png_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cc129c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guill\\OneDrive\\Documentos\\evidently\\evidently_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression v1 accuracy: 0.7241379310344828\n",
      "Logistic Regression v1 precision: 0.7037037037037037\n",
      "Logistic Regression v1 recall: 1.0\n",
      "Logistic Regression v1 roc_auc: 0.7105263157894737\n",
      "Logistic Regression v1 log_loss: 0.6482681117897063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 01:26:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RunInfo: artifact_uri='/mlflow/mlruns/4/bbce7dff3a9d42e9ad59c65a07a1cbeb/artifacts', end_time=None, experiment_id='4', lifecycle_stage='active', run_id='bbce7dff3a9d42e9ad59c65a07a1cbeb', run_name='classy-slug-608', run_uuid='bbce7dff3a9d42e9ad59c65a07a1cbeb', start_time=1746591992683, status='RUNNING', user_id='guill'>\n",
      "üèÉ View run classy-slug-608 at: http://localhost:5000/#/experiments/4/runs/bbce7dff3a9d42e9ad59c65a07a1cbeb\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import ClassificationPreset\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv(\"datasets/student-dataset-v1.csv\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Result'] = le.fit_transform(df['Result'])\n",
    "\n",
    "X = df.drop(columns=['Result'])\n",
    "y = df['Result']\n",
    "\n",
    "# Encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Add predictions and target for Evidently\n",
    "X_train['prediction'] = lr_model.predict_proba(X_train)[:, 1]\n",
    "X_test['prediction'] = lr_model.predict_proba(X_test)[:, 1]\n",
    "X_train['target'] = y_train\n",
    "X_test['target'] = y_test\n",
    "\n",
    "# Generate Evidently report\n",
    "lr_class_report = Report(metrics=[ClassificationPreset()])\n",
    "lr_class_report.run(reference_data=X_train, current_data=X_test)\n",
    "\n",
    "# Save report as JSON\n",
    "report_path = \"json_reports/lr_report_v1.json\"\n",
    "lr_class_report.save(report_path)\n",
    "\n",
    "# Load JSON data\n",
    "with open(report_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract metrics from Evidently report\n",
    "metric_results = data['suite']['metric_results']\n",
    "metrics = {}\n",
    "\n",
    "for result in metric_results:\n",
    "    if 'current' in result:\n",
    "        metrics.update(result['current'])  # Collect all metrics from 'current'\n",
    "\n",
    "# Define metrics to log (ensure they exist in the report)\n",
    "desired_metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc', 'log_loss']\n",
    "logged_metrics = {key: metrics.get(key) for key in desired_metrics if key in metrics}\n",
    "\n",
    "# Print extracted metrics\n",
    "for metric_name, metric_value in logged_metrics.items():\n",
    "    print(f\"Logistic Regression v1 {metric_name}: {metric_value}\")\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "# Log into MLflow\n",
    "client = MlflowClient()\n",
    "\n",
    "# Set experiment\n",
    "mlflow.set_experiment('Monitoring with EvidentlyAI')\n",
    "\n",
    "# Start new run\n",
    "with mlflow.start_run() as run:\n",
    "    # Log all extracted metrics\n",
    "    for metric_name, metric_value in logged_metrics.items():\n",
    "        mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(lr_model, \"logistic_regression_model\")\n",
    "\n",
    "    # Log the Evidently report as an artifact\n",
    "    mlflow.log_artifact(report_path, \"evidently_reports\")\n",
    "\n",
    "    # Print run info\n",
    "    print(run.info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITBA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
