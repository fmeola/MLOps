{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbe816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guill\\OneDrive\\Documentos\\simplegit\\ITBA\\ITBA\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MONITOREO DE RENDIMIENTO DEL MODELO CON ANÁLISIS SHAP\n",
      "==================================================\n",
      "\n",
      "Cargando datos...\n",
      "Preparando datos de referencia y actuales...\n",
      "Entrenando modelo...\n",
      "\n",
      "--------------------------------------------------\n",
      "1. MÉTRICAS DE RENDIMIENTO DEL MODELO\n",
      "--------------------------------------------------\n",
      "                        MSE    RMSE     MAE  MAPE (%)      R²  Var. Explicada\n",
      "Datos de Referencia  0.2565  0.5065  0.3323   19.0862  0.8046          0.8047\n",
      "Datos Actuales       0.4388  0.6624  0.4781   29.0322  0.6657          0.7372\n",
      "\n",
      "Cambios en las métricas:\n",
      "          Métrica  Referencia   Actual  Diferencia  Cambio (%)\n",
      "0             MSE      0.2565   0.4388      0.1823     71.0574\n",
      "1            RMSE      0.5065   0.6624      0.1559     30.7889\n",
      "2             MAE      0.3323   0.4781      0.1458     43.8870\n",
      "3        MAPE (%)     19.0862  29.0322      9.9460     52.1110\n",
      "4              R²      0.8046   0.6657     -0.1389    -17.2594\n",
      "5  Var. Explicada      0.8047   0.7372     -0.0675     -8.3874\n",
      "\n",
      "--------------------------------------------------\n",
      "2. ANÁLISIS AVANZADO DE DRIFT EN VARIABLES\n",
      "--------------------------------------------------\n",
      "\n",
      "Análisis de drift en variables (ordenado por severidad del drift):\n",
      "      Feature  Mean_Change(%)  KS_PValue  Wasserstein  JS_Distance Drift_Level\n",
      "0      MedInc         20.0000        0.0       0.0532       0.1393    MODERADO\n",
      "2    AveRooms          9.2461        0.0       0.0038       0.1382    MODERADO\n",
      "1    HouseAge          0.0000        1.0       0.0000       0.0000          NO\n",
      "3   AveBedrms          0.0000        1.0       0.0000       0.0000          NO\n",
      "4  Population          0.0000        1.0       0.0000       0.0000          NO\n",
      "5    AveOccup          0.0000        1.0       0.0000       0.0000          NO\n",
      "6    Latitude          0.0000        1.0       0.0000       0.0000          NO\n",
      "7   Longitude         -0.0000        1.0       0.0000       0.0000          NO\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    r2_score, \n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    explained_variance_score\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import shap\n",
    "from scipy.stats import ks_2samp, wasserstein_distance, energy_distance\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Configuración visual\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "colors = sns.color_palette(\"mako\", 10)\n",
    "\n",
    "# Establecer semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MONITOREO DE RENDIMIENTO DEL MODELO CON ANÁLISIS SHAP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Crear un directorio para las gráficas\n",
    "import os\n",
    "if not os.path.exists('model_monitoring'):\n",
    "    os.makedirs('model_monitoring')\n",
    "\n",
    "# Cargar el dataset\n",
    "print(\"\\nCargando datos...\")\n",
    "housing = fetch_california_housing()\n",
    "data = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "data['target'] = housing.target\n",
    "\n",
    "# Dividir en train/test\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Simular datos con drift para comparación\n",
    "print(\"Preparando datos de referencia y actuales...\")\n",
    "current_data = test_data.copy()\n",
    "# Introducir drift artificial en algunas características\n",
    "current_data['MedInc'] = current_data['MedInc'] * 1.2\n",
    "current_data['AveRooms'] = current_data['AveRooms'] + 0.5\n",
    "\n",
    "# Preparar conjuntos\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data['target']\n",
    "X_test = test_data.drop('target', axis=1)\n",
    "y_test = test_data['target']\n",
    "X_current = current_data.drop('target', axis=1)\n",
    "y_current = current_data['target']\n",
    "\n",
    "# Entrenar modelo\n",
    "print(\"Entrenando modelo...\")\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generar predicciones\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_current = model.predict(X_current)\n",
    "\n",
    "# Crear DataFrame de resultados\n",
    "results_test = pd.DataFrame({\n",
    "    'actual': y_test, \n",
    "    'predicted': y_pred_test, \n",
    "    'residual': y_test - y_pred_test,\n",
    "    'abs_error': np.abs(y_test - y_pred_test),\n",
    "    'pct_error': np.abs((y_test - y_pred_test) / y_test) * 100\n",
    "})\n",
    "\n",
    "results_current = pd.DataFrame({\n",
    "    'actual': y_current,\n",
    "    'predicted': y_pred_current,\n",
    "    'residual': y_current - y_pred_current,\n",
    "    'abs_error': np.abs(y_current - y_pred_current),\n",
    "    'pct_error': np.abs((y_current - y_pred_current) / y_current) * 100\n",
    "})\n",
    "\n",
    "# 1. EVALUACIÓN DEL RENDIMIENTO DEL MODELO\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"1. MÉTRICAS DE RENDIMIENTO DEL MODELO\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calcular métricas básicas\n",
    "metrics = {\n",
    "    'MSE': [mean_squared_error(y_test, y_pred_test), mean_squared_error(y_current, y_pred_current)],\n",
    "    'RMSE': [np.sqrt(mean_squared_error(y_test, y_pred_test)), np.sqrt(mean_squared_error(y_current, y_pred_current))],\n",
    "    'MAE': [mean_absolute_error(y_test, y_pred_test), mean_absolute_error(y_current, y_pred_current)],\n",
    "    'MAPE (%)': [mean_absolute_percentage_error(y_test, y_pred_test) * 100, mean_absolute_percentage_error(y_current, y_pred_current) * 100],\n",
    "    'R²': [r2_score(y_test, y_pred_test), r2_score(y_current, y_pred_current)],\n",
    "    'Var. Explicada': [explained_variance_score(y_test, y_pred_test), explained_variance_score(y_current, y_pred_current)]\n",
    "}\n",
    "\n",
    "# Crear tabla comparativa de métricas\n",
    "metrics_df = pd.DataFrame(metrics, index=['Datos de Referencia', 'Datos Actuales'])\n",
    "print(metrics_df.round(4))\n",
    "\n",
    "# Calcular diferencias\n",
    "diff_df = pd.DataFrame({\n",
    "    'Métrica': metrics_df.columns,\n",
    "    'Referencia': metrics_df.iloc[0].values,\n",
    "    'Actual': metrics_df.iloc[1].values,\n",
    "    'Diferencia': metrics_df.iloc[1].values - metrics_df.iloc[0].values,\n",
    "    'Cambio (%)': (metrics_df.iloc[1].values - metrics_df.iloc[0].values) / metrics_df.iloc[0].values * 100\n",
    "})\n",
    "print(\"\\nCambios en las métricas:\")\n",
    "print(diff_df.round(4))\n",
    "\n",
    "# 2. ANÁLISIS DE DRIFT AVANZADO EN VARIABLES\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"2. ANÁLISIS AVANZADO DE DRIFT EN VARIABLES\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Calcular estadísticas para cada columna\n",
    "drift_analysis = []\n",
    "\n",
    "for col in X_test.columns:\n",
    "    # Estadísticas básicas\n",
    "    ref_mean = X_test[col].mean()\n",
    "    ref_std = X_test[col].std()\n",
    "    curr_mean = X_current[col].mean()\n",
    "    curr_std = X_current[col].std()\n",
    "    \n",
    "    # Calcular métricas de cambio\n",
    "    mean_change_pct = (curr_mean - ref_mean) / ref_mean * 100 if ref_mean != 0 else np.inf\n",
    "    std_change_pct = (curr_std - ref_std) / ref_std * 100 if ref_std != 0 else np.inf\n",
    "    \n",
    "    # Test de Kolmogorov-Smirnov (medida estadística de drift)\n",
    "    ks_stat, ks_pval = ks_2samp(X_test[col], X_current[col])\n",
    "    \n",
    "    # Distancia de Wasserstein (Earth Mover's Distance)\n",
    "    w_distance = wasserstein_distance(X_test[col], X_current[col])\n",
    "    # Normalizar por el rango para hacerla comparable entre variables\n",
    "    w_distance_norm = w_distance / (X_test[col].max() - X_test[col].min())\n",
    "    \n",
    "    # Distancia Energy (más sensible que KS para distribuciones multidimensionales)\n",
    "    e_distance = energy_distance(X_test[col], X_current[col])\n",
    "    # Normalizar por el rango\n",
    "    e_distance_norm = e_distance / (X_test[col].max() - X_test[col].min())\n",
    "    \n",
    "    # Calcular distancia de Jensen-Shannon\n",
    "    min_val = min(X_test[col].min(), X_current[col].min())\n",
    "    max_val = max(X_test[col].max(), X_current[col].max())\n",
    "    x_range = np.linspace(min_val, max_val, 1000)\n",
    "    \n",
    "    # KDE para datos de referencia y actuales\n",
    "    ref_kde = gaussian_kde(X_test[col])\n",
    "    ref_pdf = ref_kde(x_range)\n",
    "    ref_pdf = ref_pdf / np.sum(ref_pdf)\n",
    "    \n",
    "    curr_kde = gaussian_kde(X_current[col])\n",
    "    curr_pdf = curr_kde(x_range)\n",
    "    curr_pdf = curr_pdf / np.sum(curr_pdf)\n",
    "    \n",
    "    js_distance = jensenshannon(ref_pdf, curr_pdf)\n",
    "    \n",
    "    # Determinar si hay drift significativo basado en múltiples criterios\n",
    "    # 1. KS p-value < 0.05 significa distribuciones estadísticamente diferentes\n",
    "    # 2. JS distance > 0.1 suele indicar drift significativo\n",
    "    # 3. Wasserstein norm > 0.1 indica cambio sustancial\n",
    "    drift_score = (\n",
    "        (1 if ks_pval < 0.05 else 0) + \n",
    "        (1 if js_distance > 0.1 else 0) + \n",
    "        (1 if w_distance_norm > 0.1 else 0)\n",
    "    )\n",
    "    \n",
    "    # Clasificación del drift\n",
    "    if drift_score == 0:\n",
    "        drift_level = \"NO\"\n",
    "    elif drift_score == 1:\n",
    "        drift_level = \"LEVE\"\n",
    "    elif drift_score == 2:\n",
    "        drift_level = \"MODERADO\"\n",
    "    else:\n",
    "        drift_level = \"SEVERO\"\n",
    "    \n",
    "    drift_analysis.append({\n",
    "        'Feature': col,\n",
    "        'Ref_Mean': ref_mean,\n",
    "        'Curr_Mean': curr_mean,\n",
    "        'Mean_Change(%)': mean_change_pct,\n",
    "        'Ref_Std': ref_std,\n",
    "        'Curr_Std': curr_std,\n",
    "        'Std_Change(%)': std_change_pct,\n",
    "        'KS_Stat': ks_stat,\n",
    "        'KS_PValue': ks_pval,\n",
    "        'Wasserstein': w_distance_norm,\n",
    "        'Energy': e_distance_norm,\n",
    "        'JS_Distance': js_distance,\n",
    "        'Drift_Score': drift_score,\n",
    "        'Drift_Level': drift_level\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con resultados de drift\n",
    "drift_df = pd.DataFrame(drift_analysis)\n",
    "drift_df = drift_df.sort_values('Drift_Score', ascending=False)\n",
    "\n",
    "print(\"\\nAnálisis de drift en variables (ordenado por severidad del drift):\")\n",
    "print(drift_df[['Feature', 'Mean_Change(%)', 'KS_PValue', 'Wasserstein', 'JS_Distance', 'Drift_Level']].round(4))\n",
    "\n",
    "# Visualizar cambios en las distribuciones para las variables con mayor drift\n",
    "top_drift_features = drift_df[drift_df['Drift_Level'] != \"NO\"]['Feature'].tolist()[:3]  # Hasta 3 con drift\n",
    "\n",
    "for feature in top_drift_features:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Histogramas con KDE\n",
    "    sns.histplot(X_test[feature], color=colors[0], label='Referencia', kde=True, alpha=0.6)\n",
    "    sns.histplot(X_current[feature], color=colors[1], label='Actual', kde=True, alpha=0.6)\n",
    "    \n",
    "    # Añadir estadísticas al gráfico\n",
    "    feature_stats = drift_df[drift_df['Feature'] == feature].iloc[0]\n",
    "    plt.title(f'Drift en {feature} (Nivel: {feature_stats[\"Drift_Level\"]})')\n",
    "    plt.text(0.02, 0.95, \n",
    "             f'KS p-valor: {feature_stats[\"KS_PValue\"]:.4f}\\n'\n",
    "             f'Jensen-Shannon: {feature_stats[\"JS_Distance\"]:.4f}\\n'\n",
    "             f'Wasserstein: {feature_stats[\"Wasserstein\"]:.4f}',\n",
    "             transform=plt.gca().transAxes, \n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'model_monitoring/drift_{feature}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Visualizar todas las métricas de drift para cada variable\n",
    "plt.figure(figsize=(14, 8))\n",
    "metrics_to_plot = ['KS_Stat', 'Wasserstein', 'JS_Distance']\n",
    "drift_plot_data = drift_df.melt(\n",
    "    id_vars=['Feature', 'Drift_Level'], \n",
    "    value_vars=metrics_to_plot,\n",
    "    var_name='Métrica', \n",
    "    value_name='Valor'\n",
    ")\n",
    "sns.barplot(data=drift_plot_data, x='Feature', y='Valor', hue='Métrica')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Comparación de métricas de drift por variable')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/drift_metrics_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. ANÁLISIS GLOBAL DE VALORES SHAP\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"3. ANÁLISIS GLOBAL DE VALORES SHAP\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Crear el explicador SHAP\n",
    "print(\"Calculando valores SHAP...\")\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calcular valores SHAP para el conjunto de referencia\n",
    "shap_values_test = explainer(X_test)\n",
    "\n",
    "# 3.1 Gráfico de resumen global (SHAP Summary Plot)\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values_test.values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title('Importancia Global de Variables (SHAP)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/shap_global_importance.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "shap.summary_plot(shap_values_test.values, X_test, show=False)\n",
    "plt.title('Impacto y Distribución de Variables (SHAP)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/shap_global_summary.png')\n",
    "plt.close()\n",
    "\n",
    "# 3.2 Gráficos de dependencia para las 3 variables más importantes\n",
    "top_features = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': np.abs(shap_values_test.values).mean(0)\n",
    "}).sort_values('Importance', ascending=False)['Feature'].head(3).tolist()\n",
    "\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    feature_idx = list(X_test.columns).index(feature)\n",
    "    shap.dependence_plot(feature_idx, shap_values_test.values, X_test, show=False)\n",
    "    plt.title(f'Gráfico de Dependencia SHAP para {feature}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'model_monitoring/shap_dependence_{feature}.png')\n",
    "    plt.close()\n",
    "\n",
    "# 3.3 Comparar valores SHAP entre datos de referencia y actuales\n",
    "print(\"\\nComparando valores SHAP entre datos de referencia y actuales...\")\n",
    "shap_values_current = explainer(X_current)\n",
    "\n",
    "# Calcular la media absoluta de los valores SHAP para cada característica\n",
    "shap_comparison = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'SHAP_Ref': np.abs(shap_values_test.values).mean(0),\n",
    "    'SHAP_Current': np.abs(shap_values_current.values).mean(0)\n",
    "})\n",
    "\n",
    "shap_comparison['SHAP_Change'] = shap_comparison['SHAP_Current'] - shap_comparison['SHAP_Ref']\n",
    "shap_comparison['SHAP_Change_Pct'] = (shap_comparison['SHAP_Change'] / shap_comparison['SHAP_Ref']) * 100\n",
    "shap_comparison = shap_comparison.sort_values('SHAP_Change_Pct', ascending=False)\n",
    "\n",
    "print(\"\\nCambios en la importancia de variables (SHAP):\")\n",
    "print(shap_comparison.round(4))\n",
    "\n",
    "# Visualizar cambios en importancia SHAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap_comp_plot = pd.melt(\n",
    "    shap_comparison, \n",
    "    id_vars=['Feature'], \n",
    "    value_vars=['SHAP_Ref', 'SHAP_Current'], \n",
    "    var_name='Dataset', \n",
    "    value_name='SHAP Value'\n",
    ")\n",
    "sns.barplot(data=shap_comp_plot, x='Feature', y='SHAP Value', hue='Dataset')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Comparación de valores SHAP entre datos de referencia y actuales')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/shap_importance_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. ANÁLISIS DE UN CASO PARTICULAR CON SHAP\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"4. ANÁLISIS DE UN CASO PARTICULAR CON SHAP\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Seleccionar un caso interesante (por ejemplo, uno con error alto)\n",
    "high_error_idx = results_current['abs_error'].idxmax()\n",
    "print(f\"\\nAnalizando el caso #{high_error_idx} (con error máximo):\")\n",
    "\n",
    "# Obtener los datos del caso\n",
    "instance = X_current.iloc[[high_error_idx]]\n",
    "instance_pred = y_pred_current[high_error_idx]\n",
    "instance_actual = y_current.iloc[high_error_idx]\n",
    "instance_error = instance_actual - instance_pred\n",
    "\n",
    "# Mostrar detalles del caso\n",
    "print(f\"\\nDetalles del caso #{high_error_idx}:\")\n",
    "for col, val in instance.iloc[0].items():\n",
    "    print(f\"- {col}: {val:.4f}\")\n",
    "print(f\"- Valor real: {instance_actual:.4f}\")\n",
    "print(f\"- Predicción: {instance_pred:.4f}\")\n",
    "print(f\"- Error: {instance_error:.4f} ({(instance_error/instance_actual)*100:.2f}%)\")\n",
    "\n",
    "# Calcular valores SHAP para este caso específico\n",
    "instance_shap = explainer(instance)\n",
    "\n",
    "# 4.1 Gráfico de fuerza (Force Plot)\n",
    "plt.figure(figsize=(20, 3))\n",
    "shap.plots.force(instance_shap[0], matplotlib=True, show=False)\n",
    "plt.title(f'Análisis de factores para el caso #{high_error_idx}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/shap_force_plot_instance.png')\n",
    "plt.close()\n",
    "\n",
    "# 4.2 Gráfico de cascada (Waterfall Plot)\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.plots.waterfall(instance_shap[0], max_display=len(X_test.columns), show=False)\n",
    "plt.title(f'Contribución de cada variable para el caso #{high_error_idx}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/shap_waterfall_instance.png')\n",
    "plt.close()\n",
    "\n",
    "# 4.3 Información detallada sobre las contribuciones de cada variable\n",
    "instance_contribution = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Value': instance.values[0],\n",
    "    'SHAP_Value': instance_shap.values[0],\n",
    "    'Abs_SHAP': np.abs(instance_shap.values[0])\n",
    "}).sort_values('Abs_SHAP', ascending=False)\n",
    "\n",
    "print(\"\\nContribución de variables para este caso específico:\")\n",
    "for i, row in instance_contribution.iterrows():\n",
    "    direction = \"aumentó\" if row['SHAP_Value'] > 0 else \"disminuyó\"\n",
    "    print(f\"- {row['Feature']} = {row['Value']:.4f} {direction} la predicción en {abs(row['SHAP_Value']):.4f}\")\n",
    "\n",
    "# 5. INTEGRACIÓN DE DRIFT Y SHAP\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"5. INTEGRACIÓN DE ANÁLISIS DE DRIFT Y SHAP\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Combinar resultados de drift y cambios en SHAP\n",
    "integrated_analysis = pd.merge(\n",
    "    drift_df[['Feature', 'Drift_Level', 'KS_PValue', 'JS_Distance']], \n",
    "    shap_comparison[['Feature', 'SHAP_Change_Pct']], \n",
    "    on='Feature'\n",
    ")\n",
    "\n",
    "# Ordenar por importancia del cambio\n",
    "integrated_analysis = integrated_analysis.sort_values('SHAP_Change_Pct', ascending=False)\n",
    "\n",
    "print(\"\\nRelación entre drift y cambios en importancia de variables:\")\n",
    "print(integrated_analysis.round(4))\n",
    "\n",
    "# Visualizar la relación entre drift y cambios en SHAP\n",
    "plt.figure(figsize=(12, 8))\n",
    "for level in ['SEVERO', 'MODERADO', 'LEVE', 'NO']:\n",
    "    level_data = integrated_analysis[integrated_analysis['Drift_Level'] == level]\n",
    "    if len(level_data) > 0:\n",
    "        plt.scatter(\n",
    "            level_data['JS_Distance'], \n",
    "            level_data['SHAP_Change_Pct'],\n",
    "            label=f'Drift {level}',\n",
    "            s=100,\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "        # Añadir etiquetas a los puntos\n",
    "        for _, row in level_data.iterrows():\n",
    "            plt.annotate(\n",
    "                row['Feature'], \n",
    "                (row['JS_Distance'], row['SHAP_Change_Pct']),\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points'\n",
    "            )\n",
    "\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=0.1, color='red', linestyle='--', alpha=0.5, label='Umbral de drift (JS)')\n",
    "plt.xlabel('Distancia Jensen-Shannon (Drift)')\n",
    "plt.ylabel('Cambio en importancia SHAP (%)')\n",
    "plt.title('Relación entre Drift y Cambios en Importancia de Variables')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_monitoring/drift_shap_relationship.png')\n",
    "plt.close()\n",
    "\n",
    "# 6. INFORME FINAL\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"6. RESUMEN DEL MONITOREO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Ver qué variables tienen drift significativo\n",
    "drift_vars = drift_df[drift_df['Drift_Level'] != 'NO']['Feature'].tolist()\n",
    "\n",
    "print(f\"\\nFecha del análisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total de instancias analizadas: {len(X_test)}\")\n",
    "\n",
    "if len(drift_vars) > 0:\n",
    "    print(f\"\\nVariables con drift detectado ({len(drift_vars)}):\")\n",
    "    for feature in drift_vars:\n",
    "        level = drift_df[drift_df['Feature'] == feature]['Drift_Level'].values[0]\n",
    "        print(f\"- {feature}: Drift {level}\")\n",
    "else:\n",
    "    print(\"\\nNo se detectó drift significativo en ninguna variable.\")\n",
    "\n",
    "# Resumen de degradación\n",
    "r2_change = metrics['R²'][1] - metrics['R²'][0]\n",
    "rmse_change = metrics['RMSE'][1] - metrics['RMSE'][0]\n",
    "\n",
    "print(\"\\nCambios en el rendimiento del modelo:\")\n",
    "if r2_change < 0:\n",
    "    print(f\"- R² disminuyó en {abs(r2_change):.4f} ({(r2_change/metrics['R²'][0])*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"- R² aumentó en {r2_change:.4f} ({(r2_change/metrics['R²'][0])*100:.2f}%)\")\n",
    "\n",
    "if rmse_change > 0:\n",
    "    print(f\"- RMSE empeoró en {rmse_change:.4f} ({(rmse_change/metrics['RMSE'][0])*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"- RMSE mejoró en {abs(rmse_change):.4f} ({(rmse_change/metrics['RMSE'][0])*100:.2f}%)\")\n",
    "\n",
    "# Variables con mayor cambio en importancia SHAP\n",
    "top_shap_changes = shap_comparison.head(3)['Feature'].tolist()\n",
    "print(\"\\nVariables con mayor cambio en importancia:\")\n",
    "for feature in top_shap_changes:\n",
    "    change = shap_comparison[shap_comparison['Feature'] == feature]['SHAP_Change_Pct'].values[0]\n",
    "    print(f\"- {feature}: {change:.2f}% de cambio en importancia SHAP\")\n",
    "\n",
    "# Análisis de caso particular\n",
    "print(f\"\\nAnálisis de caso particular (#{high_error_idx}):\")\n",
    "top_impact = instance_contribution.head(3)['Feature'].tolist()\n",
    "print(f\"Las variables con mayor impacto en la predicción fueron: {', '.join(top_impact)}\")\n",
    "\n",
    "# Recomendaciones\n",
    "print(\"\\nRECOMENDACIONES:\")\n",
    "severe_drift = any(drift_df['Drift_Level'] == 'SEVERO')\n",
    "moderate_drift = any(drift_df['Drift_Level'] == 'MODERADO')\n",
    "\n",
    "if severe_drift and r2_change < -0.05:\n",
    "    print(\"- El modelo muestra signos de degradación significativa con drift severo.\")\n",
    "    print(\"- Se recomienda REENTRENAR el modelo con datos más recientes.\")\n",
    "    print(f\"- Variables críticas a monitorear: {', '.join(drift_df[drift_df['Drift_Level'] == 'SEVERO']['Feature'].tolist())}\")\n",
    "elif moderate_drift or severe_drift:\n",
    "    print(\"- Se detectó drift en algunas variables, con impacto moderado en rendimiento.\")\n",
    "    print(\"- Se recomienda realizar VALIDACIÓN ADICIONAL y considerar reentrenamiento.\")\n",
    "    print(f\"- Variables a monitorear: {', '.join(drift_vars[:3])}\")\n",
    "elif len(drift_vars) > 0:\n",
    "    print(\"- Se detectó drift leve en algunas variables, con impacto limitado en rendimiento.\")\n",
    "    print(\"- Monitorear el modelo en los próximos días.\")\n",
    "else:\n",
    "    print(\"- El modelo mantiene un rendimiento estable sin drift significativo.\")\n",
    "    print(\"- Continuar con el monitoreo rutinario.\")\n",
    "\n",
    "print(\"\\nGráficos generados en el directorio 'model_monitoring/'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITBA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
